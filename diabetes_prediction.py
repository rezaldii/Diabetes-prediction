# -*- coding: utf-8 -*-
"""Diabetes-prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lpOsFap39GNJpybjnYyMrYuDhyw59T3w

# Proyek Predictive Analytics: Diabetes-prediction
- Nama: Rezaldi
- Email: rezaldi30082003@students.amikom.ac.id
- Id Dicoding: rezaldi_20113717
- Dataset: https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset

## Import library
"""

import pandas as pd
import matplotlib.pyplot as plt
import scipy.stats as stats
from scipy.stats import chi2_contingency
import seaborn as sns
from sklearn.ensemble import IsolationForest
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import cross_val_score

"""## Data Understanding

### Data Collection
"""

# Load the dataset into a DataFrame
data = pd.read_csv('diabetes_prediction_dataset.csv')
# Display the first 5 rows of the data
data.head()

"""Setiap baris dalam output mewakili data pasien dengan berbagai atribut, termasuk informasi tentang jenis kelamin, usia, hipertensi, penyakit jantung, riwayat merokok, indeks massa tubuh (BMI), tingkat HbA1c, tingkat glukosa darah, dan apakah pasien tersebut memiliki diabetes atau tidak (kolom "diabetes").

### Data Description
"""

# Display the shape of the data
print(f'The dataset contains {data.shape[0]} rows and {data.shape[1]} columns.')

"""Output memberikan informasi tentang ukuran (shape) dari dataset. Dalam hal ini, mengetahui bahwa dataset ini memiliki 100,000 baris (rows) dan 9 kolom (columns)."""

# Display the data types of each column
print('\nThe data types of each column are:')
print(data.dtypes)

"""Output memberikan informasi tentang tipe data (data types) dari setiap kolom dalam dataset. Berikut adalah penjelasan singkat dari tipe data masing-masing kolom:

1. `gender`: Kolom ini memiliki tipe data "object," yang biasanya digunakan untuk data teks atau kategori. Ini mungkin berisi informasi tentang jenis kelamin pasien.

2. `age`: Kolom ini memiliki tipe data "float64," yang berarti itu adalah data numerik berupa angka desimal. Ini mungkin berisi informasi tentang usia pasien.

3. `hypertension`: Kolom ini memiliki tipe data "int64," yang berarti itu adalah data numerik berupa bilangan bulat. Ini mungkin berisi informasi tentang apakah pasien memiliki hipertensi (1 untuk ya, 0 untuk tidak).

4. `heart_disease`: Kolom ini juga memiliki tipe data "int64" dan mungkin berisi informasi tentang apakah pasien memiliki penyakit jantung (1 untuk ya, 0 untuk tidak).

5. `smoking_history`: Kolom ini memiliki tipe data "object," yang mungkin berisi informasi tentang riwayat merokok pasien dalam bentuk teks atau kategori.

6. `bmi`: Kolom ini memiliki tipe data "float64" dan mungkin berisi informasi tentang Indeks Massa Tubuh (BMI) pasien.

7. `HbA1c_level`: Kolom ini memiliki tipe data "float64" dan mungkin berisi informasi tentang tingkat HbA1c dalam darah pasien.

8. `blood_glucose_level`: Kolom ini memiliki tipe data "int64" dan mungkin berisi informasi tentang tingkat glukosa darah pasien.

9. `diabetes`: Kolom ini memiliki tipe data "int64" dan mungkin berisi informasi tentang apakah pasien memiliki diabetes (1 untuk ya, 0 untuk tidak).
"""

# Display summary statistics for the numerical columns
data.describe()

"""Output tersebut adalah ringkasan statistik untuk kolom-kolom numerik dalam dataset. Berikut adalah penjelasan singkat dari statistik yang diberikan:

- `count`: Menunjukkan jumlah data yang tersedia untuk setiap kolom. Semua kolom memiliki 100,000 entri, yang menunjukkan bahwa tidak ada nilai yang hilang (missing values) dalam dataset ini.

- `mean`: Ini adalah rata-rata dari setiap kolom numerik. Misalnya, rata-rata usia pasien adalah sekitar 41.89 tahun, rata-rata BMI adalah sekitar 27.32, dan sebagainya.

- `std`: Ini adalah simpangan baku (standard deviation) dari setiap kolom numerik. Simpangan baku mengukur sebaran data dari nilai rata-rata. Semakin tinggi nilai simpangan baku, semakin besar variasi data. Misalnya, simpangan baku dari usia adalah sekitar 22.52, yang menunjukkan variasi yang signifikan dalam usia pasien.

- `min`: Ini adalah nilai minimum dalam setiap kolom. Misalnya, nilai usia minimum adalah 0.08 tahun, nilai minimum BMI adalah 10.01, dan seterusnya.

- `25%`, `50%`, dan `75%`: Ini adalah kuartil pertama (25th percentile), kuartil kedua (median, 50th percentile), dan kuartil ketiga (75th percentile) dari data. Kuartil adalah pengukuran yang membagi data menjadi empat bagian sama besar. Misalnya, kuartil pertama untuk usia adalah 24 tahun, yang berarti 25% dari pasien memiliki usia kurang dari 24 tahun.

- `max`: Ini adalah nilai maksimum dalam setiap kolom. Misalnya, nilai usia maksimum adalah 80 tahun, nilai maksimum BMI adalah 95.69, dan sebagainya.
"""

# Display the number of missing values in each column
print('Number of missing values in each column:')
print(data.isnull().sum())

"""Dataset ini sudah bersih dari nilai yang hilang dalam semua kolomnya. Tidak ada kolom dengan nilai yang hilang, sehingga tidak perlu dilakukan tindakan pengisian nilai yang hilang."""

# Display the number of unique values in each column
print('\nNumber of unique values in each column:')
print(data.nunique())

"""Output menunjukkan jumlah nilai unik (unique values) dalam setiap kolom dataset. Dalam hal ini, hasilnya adalah sebagai berikut:

- Kolom 'gender' memiliki 3 nilai unik.
- Kolom 'age' memiliki 102 nilai unik.
- Kolom 'hypertension' memiliki 2 nilai unik, yang mungkin mencerminkan apakah seseorang menderita hipertensi atau tidak.
- Kolom 'heart_disease' memiliki 2 nilai unik, yang mungkin mencerminkan apakah seseorang memiliki penyakit jantung atau tidak.
- Kolom 'smoking_history' memiliki 6 nilai unik, yang mungkin mencerminkan sejarah merokok seseorang.
- Kolom 'bmi' memiliki 4,247 nilai unik, yang mencerminkan berbagai nilai indeks massa tubuh (BMI) yang berbeda.
- Kolom 'HbA1c_level' memiliki 18 nilai unik, yang mungkin mencerminkan tingkat HbA1c dalam darah.
- Kolom 'blood_glucose_level' memiliki 18 nilai unik, yang mungkin mencerminkan tingkat glukosa dalam darah.
- Kolom 'diabetes' memiliki 2 nilai unik, yang mungkin mencerminkan apakah seseorang memiliki diabetes atau tidak.
"""

# Display the frequency counts for categorical columns
for col in data.select_dtypes(include='object').columns:
    print(f'\nFrequency counts for {col}:')
    print(data[col].value_counts())

"""- Kolom 'gender' memiliki tiga nilai kategori: Female, Male, dan Other. Female adalah yang paling umum dengan jumlah kemunculan terbanyak.
- Kolom 'smoking_history' mencerminkan sejarah merokok, dan sebagian besar data dalam kolom ini memiliki nilai "No Info" atau "never," yang mungkin mencerminkan ketidaktersediaan informasi atau bahwa sebagian besar responden tidak merokok. Ada juga beberapa yang telah merokok di masa lalu (former) atau saat ini (current).

### Exploratory Data Analysis (EDA)

#### Data visualization
"""

# Grafik batang untuk variabel jenis kelamin (gender)
gender_counts = data['gender'].value_counts()
plt.bar(gender_counts.index, gender_counts.values)
plt.xlabel('Gender')
plt.ylabel('Count')
plt.title('Frequency of Gender')
plt.show()

# Grafik batang untuk variabel riwayat merokok (smoking_history)
smoking_counts = data['smoking_history'].value_counts()
plt.bar(smoking_counts.index, smoking_counts.values)
plt.xlabel('Smoking History')
plt.ylabel('Count')
plt.title('Frequency of Smoking History')
plt.show()

# Histogram untuk variabel usia (age)
plt.hist(data['age'], bins=10)
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.title('Distribution of Age')
plt.show()

# Histogram untuk variabel indeks massa tubuh (bmi)
plt.hist(data['bmi'], bins=10)
plt.xlabel('BMI')
plt.ylabel('Frequency')
plt.title('Distribution of BMI')
plt.show()

# Histogram untuk variabel tingkat glukosa darah (blood_glucose_level)
plt.hist(data['blood_glucose_level'], bins=10)
plt.xlabel('Blood Glucose Level')
plt.ylabel('Frequency')
plt.title('Distribution of Blood Glucose Level')
plt.show()

# Boxplot untuk variabel usia (age)
plt.boxplot(data['age'])
plt.xlabel('Age')
plt.title('Boxplot of Age')
plt.show()

# Boxplot untuk variabel indeks massa tubuh (bmi)
plt.boxplot(data['bmi'])
plt.xlabel('BMI')
plt.title('Boxplot of BMI')
plt.show()

# Boxplot untuk variabel tingkat glukosa darah (blood_glucose_level)
plt.boxplot(data['blood_glucose_level'])
plt.xlabel('Blood Glucose Level')
plt.title('Boxplot of Blood Glucose Level')
plt.show()

# Scatterplot untuk hubungan antara usia (age) dan indeks massa tubuh (bmi)
plt.scatter(data['age'], data['bmi'])
plt.xlabel('Age')
plt.ylabel('BMI')
plt.title('Scatterplot of Age vs BMI')
plt.show()

"""#### Pengujian hipotesis statistik"""

# Pisahkan data menjadi dua kelompok berdasarkan diabetes
diabetes_group = data[data['diabetes'] == 1]
non_diabetes_group = data[data['diabetes'] == 0]

# Lakukan uji t
t_statistic, p_value = stats.ttest_ind(diabetes_group['bmi'], non_diabetes_group['bmi'], equal_var=False)

# Tampilkan hasil uji
print(f'T-Statistic: {t_statistic}')
print(f'P-Value: {p_value}')

# Ambil alpha level (biasanya 0.05)
alpha = 0.05

# Tentukan apakah hasil uji statistik signifikan
if p_value < alpha:
    print('Terdapat perbedaan signifikan dalam rata-rata BMI antara pasien diabetes dan non-diabetes.')
else:
    print('Tidak terdapat perbedaan signifikan dalam rata-rata BMI antara pasien diabetes dan non-diabetes.')

"""- P-value sangat kecil (kurang dari alpha 0.05), sehingga dapat menolak hipotesis nol.
- Dengan kata lain, hasil ini menunjukkan adanya perbedaan yang signifikan dalam rata-rata BMI antara pasien diabetes dan pasien non-diabetes.
- Ini menunjukkan bahwa BMI dapat menjadi faktor yang signifikan dalam membedakan antara kedua kelompok ini.
"""

# Pisahkan data menjadi kelompok berdasarkan riwayat merokok
groups = [data[data['smoking_history'] == 'never']['bmi'],
          data[data['smoking_history'] == 'former']['bmi'],
          data[data['smoking_history'] == 'current']['bmi']]

# Lakukan uji ANOVA
f_statistic, p_value = stats.f_oneway(*groups)

# Tampilkan hasil uji
print(f'F-Statistic: {f_statistic}')
print(f'P-Value: {p_value}')

# Ambil alpha level (biasanya 0.05)
alpha = 0.05

# Tentukan apakah hasil uji statistik signifikan
if p_value < alpha:
    print('Terdapat perbedaan signifikan dalam rata-rata BMI antara kelompok berbeda berdasarkan riwayat merokok.')
else:
    print('Tidak terdapat perbedaan signifikan dalam rata-rata BMI antara kelompok berbeda berdasarkan riwayat merokok.')

"""P-value yang sangat kecil (kurang dari alpha 0.05) menunjukkan bahwa terdapat perbedaan yang signifikan dalam rata-rata BMI antara ketiga kelompok berdasarkan riwayat merokok."""

# Membuat tabel kontingensi
contingency_table = pd.crosstab(data['gender'], data['diabetes'])
print(contingency_table)

"""- Tabel kontingensi ini memberikan gambaran distribusi diabetes berdasarkan jenis kelamin.
- Misalnya, terdapat 54091 wanita yang tidak memiliki diabetes (0) dan 4461 wanita yang memiliki diabetes (1).
"""

# Melakukan Pengujian Chi-square
chi2, p, dof, expected = chi2_contingency(contingency_table)
print(f"Chi-square Value: {chi2}")
print(f"P-Value: {p}")
print(f"Degrees of Freedom: {dof}")
print("Expected Frequencies Table:")
print(expected)

"""Hasil dari uji statistik Chi-square (uji chi-kuadrat) yang dilakukan untuk menguji apakah terdapat hubungan yang signifikan antara jenis kelamin ("gender") dan diabetes ("diabetes"). Berikut penjelasan singkat:

- Chi-square Value: Nilai statistik Chi-square yang dihitung dari tabel kontingensi. Nilai ini mengukur seberapa besar perbedaan antara observasi aktual dan harapan dalam tabel kontingensi. Semakin besar nilainya, semakin besar perbedaan antara kedua variabel.

- P-Value: Nilai p yang merupakan hasil dari uji statistik Chi-square. P-Value digunakan untuk menentukan apakah ada hubungan yang signifikan antara jenis kelamin dan diabetes. Semakin kecil nilai p, semakin signifikan hubungannya. Dalam kasus ini, nilai p sangat kecil, mendekati nol, yang menunjukkan adanya hubungan yang signifikan.

- Degrees of Freedom: Derajat kebebasan uji statistik Chi-square. Dalam kasus ini, terdapat 2 derajat kebebasan karena terdapat 3 kategori dalam variabel "gender" dan 2 kategori dalam variabel "diabetes."

- Expected Frequencies Table: Tabel frekuensi harapan yang menunjukkan berapa jumlah yang diharapkan dalam setiap sel tabel kontingensi jika tidak ada hubungan antara kedua variabel. Perbandingan antara observasi aktual dan harapan digunakan untuk menghitung nilai Chi-square.
"""

# Hitung korelasi antara usia (age) dan indeks massa tubuh (bmi) menggunakan metode Pearson
correlation = data['age'].corr(data['bmi'], method='pearson')

# Visualisasi scatterplot antara usia (age) dan indeks massa tubuh (bmi)
plt.figure(figsize=(8, 6))
sns.scatterplot(x='age', y='bmi', data=data)
plt.xlabel('Age')
plt.ylabel('BMI')
plt.title(f'Scatterplot of Age vs BMI (Correlation: {correlation:.2f})')
plt.show()

# Menampilkan nilai korelasi
print(f'Correlation between age and BMI: {correlation:.2f}')

"""Terdapat korelasi positif yang lemah antara usia (age) dan indeks massa tubuh (BMI) dengan nilai korelasi sekitar 0.34.

#### Deteksi anomali
"""

# Pilih variabel numerik yang ingin Anda deteksi anomali
numerical_columns = ['age', 'bmi', 'HbA1c_level', 'blood_glucose_level']

# Lakukan deteksi anomali untuk setiap variabel numerik
for column in numerical_columns:
    # Hitung kuartil pertama (Q1) dan kuartil ketiga (Q3)
    Q1 = data[column].quantile(0.25)
    Q3 = data[column].quantile(0.75)

    # Hitung IQR (Interquartile Range)
    IQR = Q3 - Q1

    # Tentukan batas bawah dan batas atas untuk deteksi anomali
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Temukan data yang di luar batas atas atau batas bawah
    anomalies = data[(data[column] < lower_bound) | (data[column] > upper_bound)]

    # Tampilkan data anomali
    print(f"Anomalous values in {column}:")
    print(anomalies)

"""Hasil dari deteksi anomali pada beberapa variabel numerik seperti usia (age), indeks massa tubuh (bmi), HbA1c level, dan kadar glukosa darah (blood glucose level) menggunakan metode IQR (Interquartile Range). Berikut penjelasan singkat:

- Variabel Age: Tidak ada nilai anomali dalam variabel usia (age). Ini berarti tidak ada data usia yang dianggap sebagai anomali berdasarkan metode IQR.

- Variabel BMI: Dalam variabel indeks massa tubuh (bmi), terdapat beberapa nilai yang dianggap anomali. Misalnya, pada baris 11, BMI mencapai 54.70, yang dianggap sebagai anomali. Ada banyak baris lain dengan nilai BMI di atas batas atas yang juga dianggap anomali.

- Variabel lainnya: Hasil deteksi anomali juga dilakukan pada variabel HbA1c level dan kadar glukosa darah (blood glucose level), tetapi output untuk kedua variabel ini tidak ditampilkan dalam contoh ini.
"""

# Select the features you want to use for anomaly detection (e.g., age and bmi)
features = ['age', 'bmi']

# Create a DataFrame with selected features
X = data[features]

# Initialize the Isolation Forest model
clf = IsolationForest(contamination=0.05, random_state=42)

# Fit the model to the data and predict anomalies
data['anomaly'] = clf.fit_predict(X)

# Anomalies are labeled as -1, so we filter the data to get only anomalies
anomalies = data[data['anomaly'] == -1]

# Print the anomalies
print("Anomalous values:")
print(anomalies)

"""### Verifikasi Kualitas Data"""

# Cek jumlah data yang duplikat
duplicate_count = data.duplicated().sum()

# Tampilkan jumlah data yang duplikat
print(f"Jumlah data yang duplikat: {duplicate_count}")

# Hapus data yang duplikat
data = data.drop_duplicates()

# Tampilkan bentuk baru dari dataset setelah menghapus data yang duplikat
print(f"Bentuk dataset setelah menghapus data yang duplikat: {data.shape}")

"""Sebanyak 3,854 data duplikat berhasil dihapus"""

# Pilih variabel numerik yang ingin Anda periksa dan atasi outlier (misalnya, age, bmi, HbA1c_level)
numerical_columns = ['age', 'bmi', 'HbA1c_level']

# Lakukan penanganan outlier untuk setiap variabel numerik
for column in numerical_columns:
    # Hitung kuartil pertama (Q1) dan kuartil ketiga (Q3)
    Q1 = data[column].quantile(0.25)
    Q3 = data[column].quantile(0.75)

    # Hitung IQR (Interquartile Range)
    IQR = Q3 - Q1

    # Tentukan batas bawah dan batas atas untuk deteksi outlier
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Gantikan nilai outlier dengan nilai batas atas atau batas bawah
    data[column] = np.where(data[column] < lower_bound, lower_bound, data[column])
    data[column] = np.where(data[column] > upper_bound, upper_bound, data[column])

# Check for inconsistencies in age (e.g., negative values)
inconsistent_age = data[data['age'] < 0]

# Check for inconsistencies in gender (e.g., unexpected values)
unexpected_gender = data[~data['gender'].isin(['Male', 'Female'])]

# Print the records with inconsistencies
print("Inconsistent Age:")
print(inconsistent_age)

print("\nUnexpected Gender:")
print(unexpected_gender)

"""- Tidak ada ketidaksesuaian dalam kolom "age," yang berarti data usia dalam kisaran yang valid.
- Terdapat ketidaksesuaian dalam kolom "gender" dengan beberapa entri yang memiliki nilai "Other." Perlu ditentukan apakah nilai ini harus dihapus atau diperbaiki untuk konsistensi data.
"""

# Mengganti "Other" dengan NaN dalam kolom "gender"
data['gender'] = data['gender'].replace('Other', np.nan)

# Menyimpan dataset yang telah diperbarui
data.to_csv('diabetes_prediction_dataset_updated.csv', index=False)

"""## Data Preparation"""

# Pilih fitur numerik yang ingin distandarisasi
numerical_features = ['age', 'bmi', 'HbA1c_level', 'blood_glucose_level']

# Inisialisasi Standard Scaler
scaler = StandardScaler()

# Lakukan standarisasi pada fitur-fitur tersebut
data[numerical_features] = scaler.fit_transform(data[numerical_features])

# Tampilkan data setelah standarisasi
print(data.head())

"""Data fitur-fitur numerik telah diubah sehingga memiliki mean (rerata) sekitar 0 dan deviasi standar sekitar 1 setelah proses standarisasi."""

# Membaca dataset yang telah diubah
data = pd.read_csv('diabetes_prediction_dataset_updated.csv')

# Melakukan one-hot encoding untuk kolom "gender" dan "smoking_history"
data_encoded = pd.get_dummies(data, columns=['gender', 'smoking_history'], drop_first=True)

# Menampilkan lima baris pertama dari dataset yang telah di-encode
print(data_encoded.head())

# Simpan dataset yang telah di-encode
data_encoded.to_csv('diabetes_prediction_dataset_encoded.csv', index=False)

"""Dataset telah berhasil dienkripsi dengan one-hot encoding, dan hasilnya tersimpan"""

# Membaca dataset yang telah diencode
data_encoded = pd.read_csv('diabetes_prediction_dataset_encoded.csv')

# Menghitung korelasi antara fitur dan target (diabetes)
correlations = data_encoded.corr()['diabetes'].abs().sort_values(ascending=False)

# Menentukan ambang batas korelasi yang relevan (misalnya, 0.1)
relevant_features = correlations[correlations > 0.1].index.tolist()

# Menampilkan fitur-fitur yang memiliki korelasi relevan
print("Fitur-fitur yang memiliki korelasi relevan dengan diabetes:")
print(relevant_features)

# Memvisualisasikan matriks korelasi
corr_matrix = data_encoded[relevant_features].corr()
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Matriks Korelasi Fitur-fitur yang Relevan')
plt.show()

"""Fitur-fitur yang memiliki korelasi relevan dengan "diabetes" adalah 'blood_glucose_level', 'HbA1c_level', 'age', 'bmi', 'hypertension', dan 'heart_disease'."""

# Memisahkan fitur (X) dan target (y)
X = data_encoded[['blood_glucose_level', 'HbA1c_level', 'age', 'bmi', 'hypertension', 'heart_disease']]
y = data_encoded['diabetes']

# Memisahkan data menjadi set pelatihan dan set tes (misalnya, 80% pelatihan dan 20% tes)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Menampilkan jumlah sampel dalam set pelatihan dan set tes
print("Jumlah sampel dalam set pelatihan:", len(X_train))
print("Jumlah sampel dalam set tes:", len(X_test))

"""Dataset telah berhasil dibagi menjadi set pelatihan dan set tes dengan proporsi 80% pelatihan dan 20% tes.

## Modeling
"""

# Inisialisasi model Regresi Logistik
logistic_regression_model = LogisticRegression(random_state=42)

# Melatih model pada set pelatihan
logistic_regression_model.fit(X_train, y_train)

# Memprediksi kelas target pada set tes
y_pred = logistic_regression_model.predict(X_test)

# Menghitung akurasi model
accuracy = accuracy_score(y_test, y_pred)
print("Akurasi model Regresi Logistik:", accuracy)

# Menampilkan laporan klasifikasi
classification_rep = classification_report(y_test, y_pred)
print("Laporan Klasifikasi:\n", classification_rep)

# Menghitung dan menampilkan matriks konfusi
conf_matrix = confusion_matrix(y_test, y_pred)
print("Matriks Konfusi:\n", conf_matrix)

"""- Model Regresi Logistik memiliki akurasi yang baik dalam memprediksi diabetes pada dataset ini.
- Meskipun presisi dan recall untuk kelas diabetes (1) lebih rendah daripada kelas tidak diabetes (0), model masih dapat dengan baik mengidentifikasi sebagian besar kasus diabetes.
"""

# Daftar hyperparameter yang akan disetel
param_grid = {
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'criterion': ['gini', 'entropy']
}

# Inisialisasi model Pohon Keputusan
decision_tree_model = DecisionTreeClassifier(random_state=42)

# Inisialisasi Grid Search
grid_search = GridSearchCV(estimator=decision_tree_model, param_grid=param_grid,
                           scoring='accuracy', cv=5, n_jobs=-1)

# Melatih model dengan Grid Search
grid_search.fit(X_train, y_train)

# Mendapatkan model terbaik setelah penyetelan
best_decision_tree_model = grid_search.best_estimator_

# Memprediksi kelas target pada set tes
y_pred_best_dt = best_decision_tree_model.predict(X_test)

# Menghitung akurasi model Pohon Keputusan setelah penyetelan
accuracy_best_dt = accuracy_score(y_test, y_pred_best_dt)
print("Akurasi model Pohon Keputusan setelah penyetelan:", accuracy_best_dt)

# Menampilkan laporan klasifikasi setelah penyetelan
classification_rep_best_dt = classification_report(y_test, y_pred_best_dt)
print("Laporan Klasifikasi Pohon Keputusan setelah penyetelan:\n", classification_rep_best_dt)

# Menghitung dan menampilkan matriks konfusi setelah penyetelan
conf_matrix_best_dt = confusion_matrix(y_test, y_pred_best_dt)
print("Matriks Konfusi Pohon Keputusan setelah penyetelan:\n", conf_matrix_best_dt)

"""- Setelah penyetelan hyperparameter, model Pohon Keputusan memiliki akurasi yang sangat baik dalam memprediksi diabetes pada dataset ini.
- Model ini memiliki presisi dan recall yang tinggi untuk kelas tidak diabetes (0), menunjukkan kemampuan yang baik dalam mengidentifikasi non-diabetes.
- Meskipun recall untuk kelas diabetes (1) lebih rendah setelah penyetelan, model ini masih dapat dengan baik mengidentifikasi sebagian besar kasus diabetes.
"""

# Menentukan grid parameter yang akan diuji
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Inisialisasi model Random Forest
random_forest_model = RandomForestClassifier(random_state=42)

# Membuat objek GridSearchCV
grid_search = GridSearchCV(estimator=random_forest_model, param_grid=param_grid,
                           scoring='accuracy', cv=3, verbose=2, n_jobs=-1)

# Melakukan penyetelan hyperparameter pada set pelatihan
grid_search.fit(X_train, y_train)

# Menampilkan parameter terbaik
print("Parameter terbaik:", grid_search.best_params_)

# Membuat model dengan parameter terbaik
best_rf_model = grid_search.best_estimator_

# Memprediksi kelas target pada set tes
y_pred_best_rf = best_rf_model.predict(X_test)

# Menghitung akurasi model Random Forest yang ditingkatkan
accuracy_best_rf = accuracy_score(y_test, y_pred_best_rf)
print("Akurasi model Random Forest yang ditingkatkan:", accuracy_best_rf)

# Menampilkan laporan klasifikasi
classification_rep_best_rf = classification_report(y_test, y_pred_best_rf)
print("Laporan Klasifikasi Random Forest yang ditingkatkan:\n", classification_rep_best_rf)

# Menghitung dan menampilkan matriks konfusi
conf_matrix_best_rf = confusion_matrix(y_test, y_pred_best_rf)
print("Matriks Konfusi Random Forest yang ditingkatkan:\n", conf_matrix_best_rf)

"""- Setelah penyetelan hyperparameter, model Random Forest memiliki akurasi yang sangat baik dalam memprediksi diabetes pada dataset ini.
- Model ini memiliki presisi dan recall yang tinggi untuk kelas tidak diabetes (0), menunjukkan kemampuan yang baik dalam mengidentifikasi non-diabetes.
- Meskipun recall untuk kelas diabetes (1) lebih rendah daripada kelas 0, model ini masih dapat dengan baik mengidentifikasi sebagian besar kasus diabetes.

## Evaluation
"""

# Evaluasi model Regresi Logistik
accuracy_lr = accuracy_score(y_test, y_pred)
precision_lr = precision_score(y_test, y_pred)
recall_lr = recall_score(y_test, y_pred)
f1_score_lr = f1_score(y_test, y_pred)

print("Evaluasi model Regresi Logistik:")
print("Akurasi:", accuracy_lr)
print("Presisi (Precision):", precision_lr)
print("Recall:", recall_lr)
print("F1-Score:", f1_score_lr)

# Evaluasi model Pohon Keputusan (setelah penyetelan)
accuracy_dt = accuracy_score(y_test, y_pred_best_dt)
precision_dt = precision_score(y_test, y_pred_best_dt)
recall_dt = recall_score(y_test, y_pred_best_dt)
f1_score_dt = f1_score(y_test, y_pred_best_dt)

print("\nEvaluasi model Pohon Keputusan (setelah penyetelan):")
print("Akurasi:", accuracy_dt)
print("Presisi (Precision):", precision_dt)
print("Recall:", recall_dt)
print("F1-Score:", f1_score_dt)

# Evaluasi model Random Forest (setelah penyetelan)
accuracy_rf = accuracy_score(y_test, y_pred_best_rf)
precision_rf = precision_score(y_test, y_pred_best_rf)
recall_rf = recall_score(y_test, y_pred_best_rf)
f1_score_rf = f1_score(y_test, y_pred_best_rf)

print("\nEvaluasi model Random Forest (setelah penyetelan):")
print("Akurasi:", accuracy_rf)
print("Presisi (Precision):", precision_rf)
print("Recall:", recall_rf)
print("F1-Score:", f1_score_rf)

"""**Evaluasi model Regresi Logistik:**
- Akurasi: 0.957
- Presisi: 0.852
- Recall: 0.628
- F1-Score: 0.723

**Evaluasi model Pohon Keputusan (setelah penyetelan):**
- Akurasi: 0.970
- Presisi: 0.991
- Recall: 0.675
- F1-Score: 0.803

**Evaluasi model Random Forest (setelah penyetelan):**
- Akurasi: 0.971
- Presisi: 0.997
- Recall: 0.673
- F1-Score: 0.804

Kesimpulan:
- Ketiga model (Regresi Logistik, Pohon Keputusan setelah penyetelan, dan Random Forest setelah penyetelan) memiliki akurasi yang tinggi, dengan akurasi tertinggi dimiliki oleh model Random Forest yang ditingkatkan.
- Model Random Forest yang ditingkatkan juga memiliki presisi dan recall yang baik untuk kedua kelas.
- Dalam kasus ini, presisi dan recall untuk kelas 1 (diabetes) adalah metrik yang relevan, dan model Random Forest yang ditingkatkan memberikan kinerja yang baik dalam mengidentifikasi kasus diabetes.
- Kinerja model Pohon Keputusan juga baik setelah penyetelan, tetapi model Random Forest yang ditingkatkan memiliki kinerja yang sedikit lebih baik.
"""

# Regresi Logistik
cv_scores_lr = cross_val_score(logistic_regression_model, X, y, cv=5)
avg_cv_score_lr = cv_scores_lr.mean()

# Pohon Keputusan (setelah penyetelan)
cv_scores_dt = cross_val_score(best_decision_tree_model, X, y, cv=5)
avg_cv_score_dt = cv_scores_dt.mean()

# Random Forest (setelah penyetelan)
cv_scores_rf = cross_val_score(best_rf_model, X, y, cv=5)
avg_cv_score_rf = cv_scores_rf.mean()

print("Evaluasi model dengan Cross-Validation:")
print("Regresi Logistik (Rata-rata CV Score):", avg_cv_score_lr)
print("Pohon Keputusan (Rata-rata CV Score):", avg_cv_score_dt)
print("Random Forest (Rata-rata CV Score):", avg_cv_score_rf)

"""**Hasil Evaluasi dengan Cross-Validation:**
- Model Regresi Logistik memiliki rata-rata CV Score sekitar 0.958.
- Model Pohon Keputusan (setelah penyetelan) memiliki rata-rata CV Score sekitar 0.971.
- Model Random Forest (setelah penyetelan) juga memiliki rata-rata CV Score sekitar 0.971.

Kesimpulan:
- Model Pohon Keputusan dan Random Forest (setelah penyetelan) memiliki kinerja yang hampir sama tinggi dalam evaluasi dengan Cross-Validation, dengan kedua model tersebut memiliki rata-rata CV Score yang mendekati 0.971.
- Model Regresi Logistik juga memiliki kinerja yang baik dengan rata-rata CV Score sekitar 0.958, tetapi sedikit lebih rendah dibandingkan dengan model berbasis pohon (Decision Tree dan Random Forest).
- Dalam kasus ini, baik model Pohon Keputusan maupun Random Forest (setelah penyetelan) dapat dianggap sebagai pilihan yang baik berdasarkan evaluasi Cross-Validation mereka. Pemilihan antara kedua model tersebut dapat didasarkan pada kebutuhan khusus dan konteks masalah yang sedang dihadapi.
"""